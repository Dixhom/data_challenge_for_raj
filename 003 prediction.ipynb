{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Given a user’s activity, predict the likelihood of the user clicking on a search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('user-ct-test-collection-02.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make columns in a lower case. Mixed cases are hard to type. '_' added to query for it collides with pandas method 'query.'\n",
    "df.columns = ['anonid', 'query_', 'querytime', 'itemrank', 'clickurl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.querytime = pd.to_datetime(df.querytime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anonid</th>\n",
       "      <th>query_</th>\n",
       "      <th>querytime</th>\n",
       "      <th>itemrank</th>\n",
       "      <th>clickurl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>479</td>\n",
       "      <td>family guy</td>\n",
       "      <td>2006-03-01 16:01:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>479</td>\n",
       "      <td>also sprach zarathustra</td>\n",
       "      <td>2006-03-02 14:48:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>family guy movie references</td>\n",
       "      <td>2006-03-03 22:37:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://www.familyguyfiles.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>479</td>\n",
       "      <td>top grossing movies of all time</td>\n",
       "      <td>2006-03-03 22:42:42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>http://movieweb.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>479</td>\n",
       "      <td>top grossing movies of all time</td>\n",
       "      <td>2006-03-03 22:42:42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>http://www.imdb.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anonid                           query_           querytime  itemrank  \\\n",
       "0     479                       family guy 2006-03-01 16:01:20       NaN   \n",
       "1     479          also sprach zarathustra 2006-03-02 14:48:55       NaN   \n",
       "2     479      family guy movie references 2006-03-03 22:37:46       1.0   \n",
       "3     479  top grossing movies of all time 2006-03-03 22:42:42       1.0   \n",
       "4     479  top grossing movies of all time 2006-03-03 22:42:42       2.0   \n",
       "\n",
       "                        clickurl  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2  http://www.familyguyfiles.com  \n",
       "3            http://movieweb.com  \n",
       "4            http://www.imdb.com  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Feature engineering is a big part of a data science role. You will need to identify/derive additional features for this task.\n",
    "\n",
    "Features generated as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(x):\n",
    "    # get a data frame and generate features from it, return features as pd.Series\n",
    "    ret = dict()\n",
    "    ret['n_click'] = len(x)\n",
    "    ret['target'] = x.clickurl.notnull().all()\n",
    "    ret['target'] = 1 if ret['target'] else 0\n",
    "    return pd.Series(ret)\n",
    "\n",
    "# information given in advnace is anonid, query_, querytime. Group the dataframe by those features and generates additional features.\n",
    "# the only feature which can be generated from itemrank and clickurl is target.\n",
    "# This is because of leakeage. The two features are always null if the user didn't click\n",
    "df = df.groupby(['anonid','query_','querytime']).apply(feature_engineer).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate features from features such as querytime\n",
    "# features are generated by subgroups of anonid and merged into the original dataframe later\n",
    "\n",
    "def get_tally(x):\n",
    "    ret = dict()\n",
    "    ret['n_query'] = len(x)\n",
    "    q_len = x.query_.apply(lambda y: len(y))\n",
    "    ret['query_len_sum'] = q_len.sum()\n",
    "    ret['query_len_mean'] = q_len.mean()\n",
    "    q_word_len = x.query_.apply(lambda y: len(y.split(' ')))\n",
    "    ret['query_word_sum'] = q_word_len.sum()\n",
    "    ret['query_word_mean'] = q_word_len.mean()\n",
    "    ret['time_span'] = (x.querytime.max() - x.querytime.min()).seconds\n",
    "    ret['weekday_min'] = x.querytime.min().weekday()\n",
    "    ret['day_min'] = x.querytime.min().day\n",
    "    ret['month_min'] = x.querytime.min().month\n",
    "    ret['weekday_max'] = x.querytime.max().weekday()\n",
    "    ret['day_max'] = x.querytime.max().day\n",
    "    ret['month_max'] = x.querytime.max().month\n",
    "    return pd.Series(ret)\n",
    "\n",
    "tally = df.groupby('anonid').apply(get_tally)\n",
    "df = df.merge(tally, on='anonid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url_in_query'] = df.query_.str.contains('www.').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anonid</th>\n",
       "      <th>query_</th>\n",
       "      <th>querytime</th>\n",
       "      <th>n_click</th>\n",
       "      <th>target</th>\n",
       "      <th>n_query</th>\n",
       "      <th>query_len_sum</th>\n",
       "      <th>query_len_mean</th>\n",
       "      <th>query_word_sum</th>\n",
       "      <th>query_word_mean</th>\n",
       "      <th>time_span</th>\n",
       "      <th>weekday_min</th>\n",
       "      <th>day_min</th>\n",
       "      <th>month_min</th>\n",
       "      <th>weekday_max</th>\n",
       "      <th>day_max</th>\n",
       "      <th>month_max</th>\n",
       "      <th>url_in_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>479</td>\n",
       "      <td>6 6 06</td>\n",
       "      <td>2006-04-28 22:19:18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>18.579545</td>\n",
       "      <td>254.0</td>\n",
       "      <td>2.886364</td>\n",
       "      <td>31588.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>479</td>\n",
       "      <td>allegory of the cave</td>\n",
       "      <td>2006-03-06 22:03:19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>18.579545</td>\n",
       "      <td>254.0</td>\n",
       "      <td>2.886364</td>\n",
       "      <td>31588.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>also sprach zarathustra</td>\n",
       "      <td>2006-03-02 14:48:55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>18.579545</td>\n",
       "      <td>254.0</td>\n",
       "      <td>2.886364</td>\n",
       "      <td>31588.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>479</td>\n",
       "      <td>average tax refund in 2005</td>\n",
       "      <td>2006-04-07 01:54:56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>18.579545</td>\n",
       "      <td>254.0</td>\n",
       "      <td>2.886364</td>\n",
       "      <td>31588.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>479</td>\n",
       "      <td>bose</td>\n",
       "      <td>2006-03-03 23:30:11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>18.579545</td>\n",
       "      <td>254.0</td>\n",
       "      <td>2.886364</td>\n",
       "      <td>31588.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868603</th>\n",
       "      <td>24969423</td>\n",
       "      <td>my space. com</td>\n",
       "      <td>2006-05-31 19:03:32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>22.142857</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>809.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868604</th>\n",
       "      <td>24969423</td>\n",
       "      <td>my space. com 3131560415</td>\n",
       "      <td>2006-05-31 19:02:36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>22.142857</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>809.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868605</th>\n",
       "      <td>24969423</td>\n",
       "      <td>my space. com 3131560415</td>\n",
       "      <td>2006-05-31 19:03:16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>22.142857</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>809.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868606</th>\n",
       "      <td>24969423</td>\n",
       "      <td>my space.com</td>\n",
       "      <td>2006-05-31 19:12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>22.142857</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>809.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868607</th>\n",
       "      <td>24969423</td>\n",
       "      <td>my space.com 3131560415</td>\n",
       "      <td>2006-05-31 19:12:25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>22.142857</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>809.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2868608 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           anonid                      query_           querytime  n_click  \\\n",
       "0             479                      6 6 06 2006-04-28 22:19:18        1   \n",
       "1             479        allegory of the cave 2006-03-06 22:03:19        3   \n",
       "2             479     also sprach zarathustra 2006-03-02 14:48:55        1   \n",
       "3             479  average tax refund in 2005 2006-04-07 01:54:56        1   \n",
       "4             479                        bose 2006-03-03 23:30:11        1   \n",
       "...           ...                         ...                 ...      ...   \n",
       "2868603  24969423               my space. com 2006-05-31 19:03:32        1   \n",
       "2868604  24969423    my space. com 3131560415 2006-05-31 19:02:36        1   \n",
       "2868605  24969423    my space. com 3131560415 2006-05-31 19:03:16        1   \n",
       "2868606  24969423                my space.com 2006-05-31 19:12:00        1   \n",
       "2868607  24969423     my space.com 3131560415 2006-05-31 19:12:25        1   \n",
       "\n",
       "         target  n_query  query_len_sum  query_len_mean  query_word_sum  \\\n",
       "0             0     88.0         1635.0       18.579545           254.0   \n",
       "1             1     88.0         1635.0       18.579545           254.0   \n",
       "2             0     88.0         1635.0       18.579545           254.0   \n",
       "3             1     88.0         1635.0       18.579545           254.0   \n",
       "4             1     88.0         1635.0       18.579545           254.0   \n",
       "...         ...      ...            ...             ...             ...   \n",
       "2868603       1      7.0          155.0       22.142857            24.0   \n",
       "2868604       0      7.0          155.0       22.142857            24.0   \n",
       "2868605       0      7.0          155.0       22.142857            24.0   \n",
       "2868606       0      7.0          155.0       22.142857            24.0   \n",
       "2868607       0      7.0          155.0       22.142857            24.0   \n",
       "\n",
       "         query_word_mean  time_span  weekday_min  day_min  month_min  \\\n",
       "0               2.886364    31588.0          2.0      1.0        3.0   \n",
       "1               2.886364    31588.0          2.0      1.0        3.0   \n",
       "2               2.886364    31588.0          2.0      1.0        3.0   \n",
       "3               2.886364    31588.0          2.0      1.0        3.0   \n",
       "4               2.886364    31588.0          2.0      1.0        3.0   \n",
       "...                  ...        ...          ...      ...        ...   \n",
       "2868603         3.428571      809.0          2.0     31.0        5.0   \n",
       "2868604         3.428571      809.0          2.0     31.0        5.0   \n",
       "2868605         3.428571      809.0          2.0     31.0        5.0   \n",
       "2868606         3.428571      809.0          2.0     31.0        5.0   \n",
       "2868607         3.428571      809.0          2.0     31.0        5.0   \n",
       "\n",
       "         weekday_max  day_max  month_max  url_in_query  \n",
       "0                6.0     28.0        5.0             0  \n",
       "1                6.0     28.0        5.0             0  \n",
       "2                6.0     28.0        5.0             0  \n",
       "3                6.0     28.0        5.0             0  \n",
       "4                6.0     28.0        5.0             0  \n",
       "...              ...      ...        ...           ...  \n",
       "2868603          2.0     31.0        5.0             0  \n",
       "2868604          2.0     31.0        5.0             0  \n",
       "2868605          2.0     31.0        5.0             0  \n",
       "2868606          2.0     31.0        5.0             0  \n",
       "2868607          2.0     31.0        5.0             0  \n",
       "\n",
       "[2868608 rows x 18 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) How will you choose an appropriate model?\n",
    "\n",
    "I just used lightgbm. It is a gradient boosted decision tree which has quite good performance in data competition platform Kaggle. Also, it doesn't require scaling and imputation of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['anonid', 'query_', 'querytime', 'target'], axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Cross-validation is an important part of developing models. How will you cross-validate the model?\n",
    "By splitting the dataset by StratifiedKFold function, training the model and evaluate it for each split and consolidating the evaluation into one list (out of fold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) What metrics will you consider when reporting the reliability of the model?\n",
    "\n",
    "Precision. I'm not sure what the objective of predicting the likelihood of the user clicking on a search result, however, if it is for having users click advertisements, the users predicted to click on a search result should actually click it. In this case, precision is the best metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[LightGBM] [Info] Number of positive: 961197, number of negative: 1333689\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2294886, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.418843 -> initscore=-0.327525\n",
      "[LightGBM] [Info] Start training from score -0.327525\n",
      "[1]\tvalid_0's binary_logloss: 0.662311\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.649562\n",
      "[3]\tvalid_0's binary_logloss: 0.638912\n",
      "[4]\tvalid_0's binary_logloss: 0.630717\n",
      "[5]\tvalid_0's binary_logloss: 0.624077\n",
      "[6]\tvalid_0's binary_logloss: 0.618363\n",
      "[7]\tvalid_0's binary_logloss: 0.614543\n",
      "[8]\tvalid_0's binary_logloss: 0.610594\n",
      "[9]\tvalid_0's binary_logloss: 0.607319\n",
      "[10]\tvalid_0's binary_logloss: 0.605476\n",
      "[11]\tvalid_0's binary_logloss: 0.603046\n",
      "[12]\tvalid_0's binary_logloss: 0.601299\n",
      "[13]\tvalid_0's binary_logloss: 0.599717\n",
      "[14]\tvalid_0's binary_logloss: 0.598427\n",
      "[15]\tvalid_0's binary_logloss: 0.597297\n",
      "[16]\tvalid_0's binary_logloss: 0.596413\n",
      "[17]\tvalid_0's binary_logloss: 0.595117\n",
      "[18]\tvalid_0's binary_logloss: 0.59426\n",
      "[19]\tvalid_0's binary_logloss: 0.593476\n",
      "[20]\tvalid_0's binary_logloss: 0.592921\n",
      "[21]\tvalid_0's binary_logloss: 0.592903\n",
      "[22]\tvalid_0's binary_logloss: 0.592213\n",
      "[23]\tvalid_0's binary_logloss: 0.591895\n",
      "[24]\tvalid_0's binary_logloss: 0.592202\n",
      "[25]\tvalid_0's binary_logloss: 0.593176\n",
      "[26]\tvalid_0's binary_logloss: 0.59332\n",
      "[27]\tvalid_0's binary_logloss: 0.59298\n",
      "[28]\tvalid_0's binary_logloss: 0.592716\n",
      "[29]\tvalid_0's binary_logloss: 0.593273\n",
      "[30]\tvalid_0's binary_logloss: 0.593603\n",
      "[31]\tvalid_0's binary_logloss: 0.593399\n",
      "[32]\tvalid_0's binary_logloss: 0.59347\n",
      "[33]\tvalid_0's binary_logloss: 0.593352\n",
      "[34]\tvalid_0's binary_logloss: 0.593808\n",
      "[35]\tvalid_0's binary_logloss: 0.594635\n",
      "[36]\tvalid_0's binary_logloss: 0.594525\n",
      "[37]\tvalid_0's binary_logloss: 0.59457\n",
      "[38]\tvalid_0's binary_logloss: 0.594726\n",
      "[39]\tvalid_0's binary_logloss: 0.59502\n",
      "[40]\tvalid_0's binary_logloss: 0.595115\n",
      "[41]\tvalid_0's binary_logloss: 0.59526\n",
      "[42]\tvalid_0's binary_logloss: 0.595943\n",
      "[43]\tvalid_0's binary_logloss: 0.596337\n",
      "[44]\tvalid_0's binary_logloss: 0.596821\n",
      "[45]\tvalid_0's binary_logloss: 0.596972\n",
      "[46]\tvalid_0's binary_logloss: 0.597167\n",
      "[47]\tvalid_0's binary_logloss: 0.598831\n",
      "[48]\tvalid_0's binary_logloss: 0.598848\n",
      "[49]\tvalid_0's binary_logloss: 0.598842\n",
      "[50]\tvalid_0's binary_logloss: 0.59902\n",
      "[51]\tvalid_0's binary_logloss: 0.600033\n",
      "[52]\tvalid_0's binary_logloss: 0.600876\n",
      "[53]\tvalid_0's binary_logloss: 0.600938\n",
      "[54]\tvalid_0's binary_logloss: 0.601164\n",
      "[55]\tvalid_0's binary_logloss: 0.60143\n",
      "[56]\tvalid_0's binary_logloss: 0.602142\n",
      "[57]\tvalid_0's binary_logloss: 0.602159\n",
      "[58]\tvalid_0's binary_logloss: 0.602759\n",
      "[59]\tvalid_0's binary_logloss: 0.603282\n",
      "[60]\tvalid_0's binary_logloss: 0.603281\n",
      "[61]\tvalid_0's binary_logloss: 0.604115\n",
      "[62]\tvalid_0's binary_logloss: 0.604323\n",
      "[63]\tvalid_0's binary_logloss: 0.60569\n",
      "[64]\tvalid_0's binary_logloss: 0.605763\n",
      "[65]\tvalid_0's binary_logloss: 0.606309\n",
      "[66]\tvalid_0's binary_logloss: 0.606432\n",
      "[67]\tvalid_0's binary_logloss: 0.60665\n",
      "[68]\tvalid_0's binary_logloss: 0.607386\n",
      "[69]\tvalid_0's binary_logloss: 0.608042\n",
      "[70]\tvalid_0's binary_logloss: 0.608771\n",
      "[71]\tvalid_0's binary_logloss: 0.610196\n",
      "[72]\tvalid_0's binary_logloss: 0.610576\n",
      "[73]\tvalid_0's binary_logloss: 0.610727\n",
      "[74]\tvalid_0's binary_logloss: 0.610981\n",
      "[75]\tvalid_0's binary_logloss: 0.611694\n",
      "[76]\tvalid_0's binary_logloss: 0.611942\n",
      "[77]\tvalid_0's binary_logloss: 0.612281\n",
      "[78]\tvalid_0's binary_logloss: 0.612797\n",
      "[79]\tvalid_0's binary_logloss: 0.612777\n",
      "[80]\tvalid_0's binary_logloss: 0.613024\n",
      "[81]\tvalid_0's binary_logloss: 0.612938\n",
      "[82]\tvalid_0's binary_logloss: 0.613434\n",
      "[83]\tvalid_0's binary_logloss: 0.614139\n",
      "[84]\tvalid_0's binary_logloss: 0.614784\n",
      "[85]\tvalid_0's binary_logloss: 0.614806\n",
      "[86]\tvalid_0's binary_logloss: 0.61502\n",
      "[87]\tvalid_0's binary_logloss: 0.615077\n",
      "[88]\tvalid_0's binary_logloss: 0.615253\n",
      "[89]\tvalid_0's binary_logloss: 0.615255\n",
      "[90]\tvalid_0's binary_logloss: 0.615878\n",
      "[91]\tvalid_0's binary_logloss: 0.615916\n",
      "[92]\tvalid_0's binary_logloss: 0.615973\n",
      "[93]\tvalid_0's binary_logloss: 0.616132\n",
      "[94]\tvalid_0's binary_logloss: 0.616788\n",
      "[95]\tvalid_0's binary_logloss: 0.617474\n",
      "[96]\tvalid_0's binary_logloss: 0.617812\n",
      "[97]\tvalid_0's binary_logloss: 0.617912\n",
      "[98]\tvalid_0's binary_logloss: 0.618206\n",
      "[99]\tvalid_0's binary_logloss: 0.618462\n",
      "[100]\tvalid_0's binary_logloss: 0.618482\n",
      "[101]\tvalid_0's binary_logloss: 0.61854\n",
      "[102]\tvalid_0's binary_logloss: 0.618533\n",
      "[103]\tvalid_0's binary_logloss: 0.618525\n",
      "[104]\tvalid_0's binary_logloss: 0.618649\n",
      "[105]\tvalid_0's binary_logloss: 0.618623\n",
      "[106]\tvalid_0's binary_logloss: 0.619054\n",
      "[107]\tvalid_0's binary_logloss: 0.619673\n",
      "[108]\tvalid_0's binary_logloss: 0.619733\n",
      "[109]\tvalid_0's binary_logloss: 0.620385\n",
      "[110]\tvalid_0's binary_logloss: 0.620928\n",
      "[111]\tvalid_0's binary_logloss: 0.621362\n",
      "[112]\tvalid_0's binary_logloss: 0.621512\n",
      "[113]\tvalid_0's binary_logloss: 0.622339\n",
      "[114]\tvalid_0's binary_logloss: 0.622471\n",
      "[115]\tvalid_0's binary_logloss: 0.622619\n",
      "[116]\tvalid_0's binary_logloss: 0.623181\n",
      "[117]\tvalid_0's binary_logloss: 0.62321\n",
      "[118]\tvalid_0's binary_logloss: 0.624035\n",
      "[119]\tvalid_0's binary_logloss: 0.624199\n",
      "[120]\tvalid_0's binary_logloss: 0.624621\n",
      "[121]\tvalid_0's binary_logloss: 0.625135\n",
      "[122]\tvalid_0's binary_logloss: 0.625173\n",
      "[123]\tvalid_0's binary_logloss: 0.6253\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's binary_logloss: 0.591895\n",
      "<class 'numpy.ndarray'>\n",
      "[LightGBM] [Info] Number of positive: 961197, number of negative: 1333689\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1637\n",
      "[LightGBM] [Info] Number of data points in the train set: 2294886, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.418843 -> initscore=-0.327525\n",
      "[LightGBM] [Info] Start training from score -0.327525\n",
      "[1]\tvalid_0's binary_logloss: 0.662438\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.649468\n",
      "[3]\tvalid_0's binary_logloss: 0.638456\n",
      "[4]\tvalid_0's binary_logloss: 0.629531\n",
      "[5]\tvalid_0's binary_logloss: 0.621732\n",
      "[6]\tvalid_0's binary_logloss: 0.615489\n",
      "[7]\tvalid_0's binary_logloss: 0.61088\n",
      "[8]\tvalid_0's binary_logloss: 0.606816\n",
      "[9]\tvalid_0's binary_logloss: 0.603197\n",
      "[10]\tvalid_0's binary_logloss: 0.600112\n",
      "[11]\tvalid_0's binary_logloss: 0.597587\n",
      "[12]\tvalid_0's binary_logloss: 0.595086\n",
      "[13]\tvalid_0's binary_logloss: 0.593271\n",
      "[14]\tvalid_0's binary_logloss: 0.591361\n",
      "[15]\tvalid_0's binary_logloss: 0.589917\n",
      "[16]\tvalid_0's binary_logloss: 0.589238\n",
      "[17]\tvalid_0's binary_logloss: 0.588293\n",
      "[18]\tvalid_0's binary_logloss: 0.587947\n",
      "[19]\tvalid_0's binary_logloss: 0.586887\n",
      "[20]\tvalid_0's binary_logloss: 0.585979\n",
      "[21]\tvalid_0's binary_logloss: 0.586106\n",
      "[22]\tvalid_0's binary_logloss: 0.585645\n",
      "[23]\tvalid_0's binary_logloss: 0.586396\n",
      "[24]\tvalid_0's binary_logloss: 0.585967\n",
      "[25]\tvalid_0's binary_logloss: 0.586488\n",
      "[26]\tvalid_0's binary_logloss: 0.586128\n",
      "[27]\tvalid_0's binary_logloss: 0.586556\n",
      "[28]\tvalid_0's binary_logloss: 0.586333\n",
      "[29]\tvalid_0's binary_logloss: 0.586568\n",
      "[30]\tvalid_0's binary_logloss: 0.586901\n",
      "[31]\tvalid_0's binary_logloss: 0.588133\n",
      "[32]\tvalid_0's binary_logloss: 0.58813\n",
      "[33]\tvalid_0's binary_logloss: 0.588334\n",
      "[34]\tvalid_0's binary_logloss: 0.589637\n",
      "[35]\tvalid_0's binary_logloss: 0.589641\n",
      "[36]\tvalid_0's binary_logloss: 0.590043\n",
      "[37]\tvalid_0's binary_logloss: 0.590477\n",
      "[38]\tvalid_0's binary_logloss: 0.590859\n",
      "[39]\tvalid_0's binary_logloss: 0.592448\n",
      "[40]\tvalid_0's binary_logloss: 0.593115\n",
      "[41]\tvalid_0's binary_logloss: 0.593404\n",
      "[42]\tvalid_0's binary_logloss: 0.593965\n",
      "[43]\tvalid_0's binary_logloss: 0.5944\n",
      "[44]\tvalid_0's binary_logloss: 0.594585\n",
      "[45]\tvalid_0's binary_logloss: 0.595008\n",
      "[46]\tvalid_0's binary_logloss: 0.59552\n",
      "[47]\tvalid_0's binary_logloss: 0.596237\n",
      "[48]\tvalid_0's binary_logloss: 0.5965\n",
      "[49]\tvalid_0's binary_logloss: 0.597325\n",
      "[50]\tvalid_0's binary_logloss: 0.597988\n",
      "[51]\tvalid_0's binary_logloss: 0.598807\n",
      "[52]\tvalid_0's binary_logloss: 0.598985\n",
      "[53]\tvalid_0's binary_logloss: 0.598997\n",
      "[54]\tvalid_0's binary_logloss: 0.599383\n",
      "[55]\tvalid_0's binary_logloss: 0.599514\n",
      "[56]\tvalid_0's binary_logloss: 0.599696\n",
      "[57]\tvalid_0's binary_logloss: 0.600502\n",
      "[58]\tvalid_0's binary_logloss: 0.600787\n",
      "[59]\tvalid_0's binary_logloss: 0.601078\n",
      "[60]\tvalid_0's binary_logloss: 0.602161\n",
      "[61]\tvalid_0's binary_logloss: 0.602658\n",
      "[62]\tvalid_0's binary_logloss: 0.603532\n",
      "[63]\tvalid_0's binary_logloss: 0.603819\n",
      "[64]\tvalid_0's binary_logloss: 0.604249\n",
      "[65]\tvalid_0's binary_logloss: 0.604733\n",
      "[66]\tvalid_0's binary_logloss: 0.604799\n",
      "[67]\tvalid_0's binary_logloss: 0.605358\n",
      "[68]\tvalid_0's binary_logloss: 0.606375\n",
      "[69]\tvalid_0's binary_logloss: 0.606424\n",
      "[70]\tvalid_0's binary_logloss: 0.606978\n",
      "[71]\tvalid_0's binary_logloss: 0.608298\n",
      "[72]\tvalid_0's binary_logloss: 0.609264\n",
      "[73]\tvalid_0's binary_logloss: 0.610883\n",
      "[74]\tvalid_0's binary_logloss: 0.611437\n",
      "[75]\tvalid_0's binary_logloss: 0.611731\n",
      "[76]\tvalid_0's binary_logloss: 0.611782\n",
      "[77]\tvalid_0's binary_logloss: 0.612048\n",
      "[78]\tvalid_0's binary_logloss: 0.61318\n",
      "[79]\tvalid_0's binary_logloss: 0.613901\n",
      "[80]\tvalid_0's binary_logloss: 0.614341\n",
      "[81]\tvalid_0's binary_logloss: 0.614349\n",
      "[82]\tvalid_0's binary_logloss: 0.614399\n",
      "[83]\tvalid_0's binary_logloss: 0.615099\n",
      "[84]\tvalid_0's binary_logloss: 0.615641\n",
      "[85]\tvalid_0's binary_logloss: 0.615792\n",
      "[86]\tvalid_0's binary_logloss: 0.616462\n",
      "[87]\tvalid_0's binary_logloss: 0.616721\n",
      "[88]\tvalid_0's binary_logloss: 0.617181\n",
      "[89]\tvalid_0's binary_logloss: 0.617821\n",
      "[90]\tvalid_0's binary_logloss: 0.61782\n",
      "[91]\tvalid_0's binary_logloss: 0.618143\n",
      "[92]\tvalid_0's binary_logloss: 0.618221\n",
      "[93]\tvalid_0's binary_logloss: 0.618652\n",
      "[94]\tvalid_0's binary_logloss: 0.618824\n",
      "[95]\tvalid_0's binary_logloss: 0.619146\n",
      "[96]\tvalid_0's binary_logloss: 0.620278\n",
      "[97]\tvalid_0's binary_logloss: 0.620795\n",
      "[98]\tvalid_0's binary_logloss: 0.622271\n",
      "[99]\tvalid_0's binary_logloss: 0.622525\n",
      "[100]\tvalid_0's binary_logloss: 0.622783\n",
      "[101]\tvalid_0's binary_logloss: 0.622861\n",
      "[102]\tvalid_0's binary_logloss: 0.623217\n",
      "[103]\tvalid_0's binary_logloss: 0.624025\n",
      "[104]\tvalid_0's binary_logloss: 0.625565\n",
      "[105]\tvalid_0's binary_logloss: 0.625991\n",
      "[106]\tvalid_0's binary_logloss: 0.626592\n",
      "[107]\tvalid_0's binary_logloss: 0.62686\n",
      "[108]\tvalid_0's binary_logloss: 0.627823\n",
      "[109]\tvalid_0's binary_logloss: 0.629295\n",
      "[110]\tvalid_0's binary_logloss: 0.629533\n",
      "[111]\tvalid_0's binary_logloss: 0.630251\n",
      "[112]\tvalid_0's binary_logloss: 0.630393\n",
      "[113]\tvalid_0's binary_logloss: 0.630397\n",
      "[114]\tvalid_0's binary_logloss: 0.630449\n",
      "[115]\tvalid_0's binary_logloss: 0.630406\n",
      "[116]\tvalid_0's binary_logloss: 0.631805\n",
      "[117]\tvalid_0's binary_logloss: 0.632472\n",
      "[118]\tvalid_0's binary_logloss: 0.633858\n",
      "[119]\tvalid_0's binary_logloss: 0.633874\n",
      "[120]\tvalid_0's binary_logloss: 0.634867\n",
      "[121]\tvalid_0's binary_logloss: 0.634956\n",
      "[122]\tvalid_0's binary_logloss: 0.635212\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's binary_logloss: 0.585645\n",
      "<class 'numpy.ndarray'>\n",
      "[LightGBM] [Info] Number of positive: 961196, number of negative: 1333690\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2294886, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.418843 -> initscore=-0.327526\n",
      "[LightGBM] [Info] Start training from score -0.327526\n",
      "[1]\tvalid_0's binary_logloss: 0.685354\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.697864\n",
      "[3]\tvalid_0's binary_logloss: 0.713497\n",
      "[4]\tvalid_0's binary_logloss: 0.734102\n",
      "[5]\tvalid_0's binary_logloss: 0.757106\n",
      "[6]\tvalid_0's binary_logloss: 0.781905\n",
      "[7]\tvalid_0's binary_logloss: 0.808747\n",
      "[8]\tvalid_0's binary_logloss: 0.83688\n",
      "[9]\tvalid_0's binary_logloss: 0.866599\n",
      "[10]\tvalid_0's binary_logloss: 0.896272\n",
      "[11]\tvalid_0's binary_logloss: 0.927329\n",
      "[12]\tvalid_0's binary_logloss: 0.955111\n",
      "[13]\tvalid_0's binary_logloss: 0.98695\n",
      "[14]\tvalid_0's binary_logloss: 1.0153\n",
      "[15]\tvalid_0's binary_logloss: 1.04382\n",
      "[16]\tvalid_0's binary_logloss: 1.06716\n",
      "[17]\tvalid_0's binary_logloss: 1.09599\n",
      "[18]\tvalid_0's binary_logloss: 1.10911\n",
      "[19]\tvalid_0's binary_logloss: 1.14113\n",
      "[20]\tvalid_0's binary_logloss: 1.16268\n",
      "[21]\tvalid_0's binary_logloss: 1.18359\n",
      "[22]\tvalid_0's binary_logloss: 1.20768\n",
      "[23]\tvalid_0's binary_logloss: 1.21012\n",
      "[24]\tvalid_0's binary_logloss: 1.23814\n",
      "[25]\tvalid_0's binary_logloss: 1.25474\n",
      "[26]\tvalid_0's binary_logloss: 1.27705\n",
      "[27]\tvalid_0's binary_logloss: 1.27629\n",
      "[28]\tvalid_0's binary_logloss: 1.30258\n",
      "[29]\tvalid_0's binary_logloss: 1.34153\n",
      "[30]\tvalid_0's binary_logloss: 1.36719\n",
      "[31]\tvalid_0's binary_logloss: 1.37369\n",
      "[32]\tvalid_0's binary_logloss: 1.373\n",
      "[33]\tvalid_0's binary_logloss: 1.3873\n",
      "[34]\tvalid_0's binary_logloss: 1.38666\n",
      "[35]\tvalid_0's binary_logloss: 1.42082\n",
      "[36]\tvalid_0's binary_logloss: 1.42043\n",
      "[37]\tvalid_0's binary_logloss: 1.45478\n",
      "[38]\tvalid_0's binary_logloss: 1.4542\n",
      "[39]\tvalid_0's binary_logloss: 1.45646\n",
      "[40]\tvalid_0's binary_logloss: 1.45597\n",
      "[41]\tvalid_0's binary_logloss: 1.45577\n",
      "[42]\tvalid_0's binary_logloss: 1.48973\n",
      "[43]\tvalid_0's binary_logloss: 1.51861\n",
      "[44]\tvalid_0's binary_logloss: 1.51911\n",
      "[45]\tvalid_0's binary_logloss: 1.52119\n",
      "[46]\tvalid_0's binary_logloss: 1.52113\n",
      "[47]\tvalid_0's binary_logloss: 1.52123\n",
      "[48]\tvalid_0's binary_logloss: 1.55304\n",
      "[49]\tvalid_0's binary_logloss: 1.58887\n",
      "[50]\tvalid_0's binary_logloss: 1.58888\n",
      "[51]\tvalid_0's binary_logloss: 1.58922\n",
      "[52]\tvalid_0's binary_logloss: 1.58908\n",
      "[53]\tvalid_0's binary_logloss: 1.58884\n",
      "[54]\tvalid_0's binary_logloss: 1.62828\n",
      "[55]\tvalid_0's binary_logloss: 1.6282\n",
      "[56]\tvalid_0's binary_logloss: 1.62872\n",
      "[57]\tvalid_0's binary_logloss: 1.63202\n",
      "[58]\tvalid_0's binary_logloss: 1.63228\n",
      "[59]\tvalid_0's binary_logloss: 1.63566\n",
      "[60]\tvalid_0's binary_logloss: 1.63633\n",
      "[61]\tvalid_0's binary_logloss: 1.65565\n",
      "[62]\tvalid_0's binary_logloss: 1.67455\n",
      "[63]\tvalid_0's binary_logloss: 1.67467\n",
      "[64]\tvalid_0's binary_logloss: 1.67448\n",
      "[65]\tvalid_0's binary_logloss: 1.67455\n",
      "[66]\tvalid_0's binary_logloss: 1.67512\n",
      "[67]\tvalid_0's binary_logloss: 1.67474\n",
      "[68]\tvalid_0's binary_logloss: 1.67559\n",
      "[69]\tvalid_0's binary_logloss: 1.71261\n",
      "[70]\tvalid_0's binary_logloss: 1.71274\n",
      "[71]\tvalid_0's binary_logloss: 1.71258\n",
      "[72]\tvalid_0's binary_logloss: 1.71291\n",
      "[73]\tvalid_0's binary_logloss: 1.73134\n",
      "[74]\tvalid_0's binary_logloss: 1.73184\n",
      "[75]\tvalid_0's binary_logloss: 1.73219\n",
      "[76]\tvalid_0's binary_logloss: 1.73248\n",
      "[77]\tvalid_0's binary_logloss: 1.73248\n",
      "[78]\tvalid_0's binary_logloss: 1.73303\n",
      "[79]\tvalid_0's binary_logloss: 1.73312\n",
      "[80]\tvalid_0's binary_logloss: 1.73309\n",
      "[81]\tvalid_0's binary_logloss: 1.75149\n",
      "[82]\tvalid_0's binary_logloss: 1.75257\n",
      "[83]\tvalid_0's binary_logloss: 1.75268\n",
      "[84]\tvalid_0's binary_logloss: 1.7527\n",
      "[85]\tvalid_0's binary_logloss: 1.75294\n",
      "[86]\tvalid_0's binary_logloss: 1.75313\n",
      "[87]\tvalid_0's binary_logloss: 1.78671\n",
      "[88]\tvalid_0's binary_logloss: 1.78773\n",
      "[89]\tvalid_0's binary_logloss: 1.78796\n",
      "[90]\tvalid_0's binary_logloss: 1.80554\n",
      "[91]\tvalid_0's binary_logloss: 1.80565\n",
      "[92]\tvalid_0's binary_logloss: 1.80584\n",
      "[93]\tvalid_0's binary_logloss: 1.80584\n",
      "[94]\tvalid_0's binary_logloss: 1.80647\n",
      "[95]\tvalid_0's binary_logloss: 1.82606\n",
      "[96]\tvalid_0's binary_logloss: 1.82617\n",
      "[97]\tvalid_0's binary_logloss: 1.84408\n",
      "[98]\tvalid_0's binary_logloss: 1.84448\n",
      "[99]\tvalid_0's binary_logloss: 1.84515\n",
      "[100]\tvalid_0's binary_logloss: 1.84516\n",
      "[101]\tvalid_0's binary_logloss: 1.84527\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.685354\n",
      "<class 'numpy.ndarray'>\n",
      "[LightGBM] [Info] Number of positive: 961197, number of negative: 1333690\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2294887, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.418843 -> initscore=-0.327525\n",
      "[LightGBM] [Info] Start training from score -0.327525\n",
      "[1]\tvalid_0's binary_logloss: 0.690015\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.704758\n",
      "[3]\tvalid_0's binary_logloss: 0.723224\n",
      "[4]\tvalid_0's binary_logloss: 0.749165\n",
      "[5]\tvalid_0's binary_logloss: 0.775631\n",
      "[6]\tvalid_0's binary_logloss: 0.799467\n",
      "[7]\tvalid_0's binary_logloss: 0.829492\n",
      "[8]\tvalid_0's binary_logloss: 0.859113\n",
      "[9]\tvalid_0's binary_logloss: 0.887432\n",
      "[10]\tvalid_0's binary_logloss: 0.922746\n",
      "[11]\tvalid_0's binary_logloss: 0.949869\n",
      "[12]\tvalid_0's binary_logloss: 0.970981\n",
      "[13]\tvalid_0's binary_logloss: 0.996237\n",
      "[14]\tvalid_0's binary_logloss: 1.02692\n",
      "[15]\tvalid_0's binary_logloss: 1.05405\n",
      "[16]\tvalid_0's binary_logloss: 1.06175\n",
      "[17]\tvalid_0's binary_logloss: 1.09267\n",
      "[18]\tvalid_0's binary_logloss: 1.10333\n",
      "[19]\tvalid_0's binary_logloss: 1.11914\n",
      "[20]\tvalid_0's binary_logloss: 1.12888\n",
      "[21]\tvalid_0's binary_logloss: 1.15492\n",
      "[22]\tvalid_0's binary_logloss: 1.16621\n",
      "[23]\tvalid_0's binary_logloss: 1.19713\n",
      "[24]\tvalid_0's binary_logloss: 1.21269\n",
      "[25]\tvalid_0's binary_logloss: 1.24009\n",
      "[26]\tvalid_0's binary_logloss: 1.2494\n",
      "[27]\tvalid_0's binary_logloss: 1.27045\n",
      "[28]\tvalid_0's binary_logloss: 1.2688\n",
      "[29]\tvalid_0's binary_logloss: 1.28339\n",
      "[30]\tvalid_0's binary_logloss: 1.2917\n",
      "[31]\tvalid_0's binary_logloss: 1.32424\n",
      "[32]\tvalid_0's binary_logloss: 1.33767\n",
      "[33]\tvalid_0's binary_logloss: 1.35522\n",
      "[34]\tvalid_0's binary_logloss: 1.35659\n",
      "[35]\tvalid_0's binary_logloss: 1.37104\n",
      "[36]\tvalid_0's binary_logloss: 1.37392\n",
      "[37]\tvalid_0's binary_logloss: 1.39327\n",
      "[38]\tvalid_0's binary_logloss: 1.40432\n",
      "[39]\tvalid_0's binary_logloss: 1.4035\n",
      "[40]\tvalid_0's binary_logloss: 1.40566\n",
      "[41]\tvalid_0's binary_logloss: 1.43955\n",
      "[42]\tvalid_0's binary_logloss: 1.44048\n",
      "[43]\tvalid_0's binary_logloss: 1.43995\n",
      "[44]\tvalid_0's binary_logloss: 1.44039\n",
      "[45]\tvalid_0's binary_logloss: 1.47364\n",
      "[46]\tvalid_0's binary_logloss: 1.48656\n",
      "[47]\tvalid_0's binary_logloss: 1.48627\n",
      "[48]\tvalid_0's binary_logloss: 1.52213\n",
      "[49]\tvalid_0's binary_logloss: 1.52108\n",
      "[50]\tvalid_0's binary_logloss: 1.52247\n",
      "[51]\tvalid_0's binary_logloss: 1.54076\n",
      "[52]\tvalid_0's binary_logloss: 1.57516\n",
      "[53]\tvalid_0's binary_logloss: 1.57482\n",
      "[54]\tvalid_0's binary_logloss: 1.58722\n",
      "[55]\tvalid_0's binary_logloss: 1.58655\n",
      "[56]\tvalid_0's binary_logloss: 1.58641\n",
      "[57]\tvalid_0's binary_logloss: 1.59455\n",
      "[58]\tvalid_0's binary_logloss: 1.59459\n",
      "[59]\tvalid_0's binary_logloss: 1.6286\n",
      "[60]\tvalid_0's binary_logloss: 1.62875\n",
      "[61]\tvalid_0's binary_logloss: 1.65974\n",
      "[62]\tvalid_0's binary_logloss: 1.65993\n",
      "[63]\tvalid_0's binary_logloss: 1.65943\n",
      "[64]\tvalid_0's binary_logloss: 1.65929\n",
      "[65]\tvalid_0's binary_logloss: 1.68941\n",
      "[66]\tvalid_0's binary_logloss: 1.68958\n",
      "[67]\tvalid_0's binary_logloss: 1.72128\n",
      "[68]\tvalid_0's binary_logloss: 1.72156\n",
      "[69]\tvalid_0's binary_logloss: 1.72153\n",
      "[70]\tvalid_0's binary_logloss: 1.75166\n",
      "[71]\tvalid_0's binary_logloss: 1.75167\n",
      "[72]\tvalid_0's binary_logloss: 1.75148\n",
      "[73]\tvalid_0's binary_logloss: 1.75152\n",
      "[74]\tvalid_0's binary_logloss: 1.75153\n",
      "[75]\tvalid_0's binary_logloss: 1.75141\n",
      "[76]\tvalid_0's binary_logloss: 1.78363\n",
      "[77]\tvalid_0's binary_logloss: 1.78327\n",
      "[78]\tvalid_0's binary_logloss: 1.78331\n",
      "[79]\tvalid_0's binary_logloss: 1.81435\n",
      "[80]\tvalid_0's binary_logloss: 1.81446\n",
      "[81]\tvalid_0's binary_logloss: 1.81448\n",
      "[82]\tvalid_0's binary_logloss: 1.81448\n",
      "[83]\tvalid_0's binary_logloss: 1.81407\n",
      "[84]\tvalid_0's binary_logloss: 1.81393\n",
      "[85]\tvalid_0's binary_logloss: 1.81381\n",
      "[86]\tvalid_0's binary_logloss: 1.84268\n",
      "[87]\tvalid_0's binary_logloss: 1.84256\n",
      "[88]\tvalid_0's binary_logloss: 1.84223\n",
      "[89]\tvalid_0's binary_logloss: 1.87036\n",
      "[90]\tvalid_0's binary_logloss: 1.89653\n",
      "[91]\tvalid_0's binary_logloss: 1.8966\n",
      "[92]\tvalid_0's binary_logloss: 1.89635\n",
      "[93]\tvalid_0's binary_logloss: 1.89626\n",
      "[94]\tvalid_0's binary_logloss: 1.89632\n",
      "[95]\tvalid_0's binary_logloss: 1.89627\n",
      "[96]\tvalid_0's binary_logloss: 1.89606\n",
      "[97]\tvalid_0's binary_logloss: 1.89615\n",
      "[98]\tvalid_0's binary_logloss: 1.8963\n",
      "[99]\tvalid_0's binary_logloss: 1.91897\n",
      "[100]\tvalid_0's binary_logloss: 1.91899\n",
      "[101]\tvalid_0's binary_logloss: 1.9504\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.690015\n",
      "<class 'numpy.ndarray'>\n",
      "[LightGBM] [Info] Number of positive: 961197, number of negative: 1333690\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2294887, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.418843 -> initscore=-0.327525\n",
      "[LightGBM] [Info] Start training from score -0.327525\n",
      "[1]\tvalid_0's binary_logloss: 0.670612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.66671\n",
      "[3]\tvalid_0's binary_logloss: 0.667025\n",
      "[4]\tvalid_0's binary_logloss: 0.670594\n",
      "[5]\tvalid_0's binary_logloss: 0.67276\n",
      "[6]\tvalid_0's binary_logloss: 0.6816\n",
      "[7]\tvalid_0's binary_logloss: 0.68861\n",
      "[8]\tvalid_0's binary_logloss: 0.697439\n",
      "[9]\tvalid_0's binary_logloss: 0.706964\n",
      "[10]\tvalid_0's binary_logloss: 0.717762\n",
      "[11]\tvalid_0's binary_logloss: 0.724728\n",
      "[12]\tvalid_0's binary_logloss: 0.732421\n",
      "[13]\tvalid_0's binary_logloss: 0.741687\n",
      "[14]\tvalid_0's binary_logloss: 0.749372\n",
      "[15]\tvalid_0's binary_logloss: 0.760569\n",
      "[16]\tvalid_0's binary_logloss: 0.770162\n",
      "[17]\tvalid_0's binary_logloss: 0.782026\n",
      "[18]\tvalid_0's binary_logloss: 0.789829\n",
      "[19]\tvalid_0's binary_logloss: 0.796406\n",
      "[20]\tvalid_0's binary_logloss: 0.802048\n",
      "[21]\tvalid_0's binary_logloss: 0.807289\n",
      "[22]\tvalid_0's binary_logloss: 0.810362\n",
      "[23]\tvalid_0's binary_logloss: 0.816402\n",
      "[24]\tvalid_0's binary_logloss: 0.821699\n",
      "[25]\tvalid_0's binary_logloss: 0.824748\n",
      "[26]\tvalid_0's binary_logloss: 0.831298\n",
      "[27]\tvalid_0's binary_logloss: 0.835992\n",
      "[28]\tvalid_0's binary_logloss: 0.842473\n",
      "[29]\tvalid_0's binary_logloss: 0.844284\n",
      "[30]\tvalid_0's binary_logloss: 0.850536\n",
      "[31]\tvalid_0's binary_logloss: 0.854944\n",
      "[32]\tvalid_0's binary_logloss: 0.860705\n",
      "[33]\tvalid_0's binary_logloss: 0.865545\n",
      "[34]\tvalid_0's binary_logloss: 0.873465\n",
      "[35]\tvalid_0's binary_logloss: 0.879312\n",
      "[36]\tvalid_0's binary_logloss: 0.885108\n",
      "[37]\tvalid_0's binary_logloss: 0.889184\n",
      "[38]\tvalid_0's binary_logloss: 0.894377\n",
      "[39]\tvalid_0's binary_logloss: 0.897569\n",
      "[40]\tvalid_0's binary_logloss: 0.902873\n",
      "[41]\tvalid_0's binary_logloss: 0.908648\n",
      "[42]\tvalid_0's binary_logloss: 0.912872\n",
      "[43]\tvalid_0's binary_logloss: 0.919592\n",
      "[44]\tvalid_0's binary_logloss: 0.924498\n",
      "[45]\tvalid_0's binary_logloss: 0.931089\n",
      "[46]\tvalid_0's binary_logloss: 0.937072\n",
      "[47]\tvalid_0's binary_logloss: 0.944243\n",
      "[48]\tvalid_0's binary_logloss: 0.949524\n",
      "[49]\tvalid_0's binary_logloss: 0.954216\n",
      "[50]\tvalid_0's binary_logloss: 0.95886\n",
      "[51]\tvalid_0's binary_logloss: 0.965416\n",
      "[52]\tvalid_0's binary_logloss: 0.969482\n",
      "[53]\tvalid_0's binary_logloss: 0.973801\n",
      "[54]\tvalid_0's binary_logloss: 0.979831\n",
      "[55]\tvalid_0's binary_logloss: 0.984628\n",
      "[56]\tvalid_0's binary_logloss: 0.987545\n",
      "[57]\tvalid_0's binary_logloss: 0.987497\n",
      "[58]\tvalid_0's binary_logloss: 0.993233\n",
      "[59]\tvalid_0's binary_logloss: 0.993665\n",
      "[60]\tvalid_0's binary_logloss: 0.993771\n",
      "[61]\tvalid_0's binary_logloss: 0.993714\n",
      "[62]\tvalid_0's binary_logloss: 0.993481\n",
      "[63]\tvalid_0's binary_logloss: 1.0011\n",
      "[64]\tvalid_0's binary_logloss: 1.00442\n",
      "[65]\tvalid_0's binary_logloss: 1.00548\n",
      "[66]\tvalid_0's binary_logloss: 1.01272\n",
      "[67]\tvalid_0's binary_logloss: 1.01916\n",
      "[68]\tvalid_0's binary_logloss: 1.02019\n",
      "[69]\tvalid_0's binary_logloss: 1.02561\n",
      "[70]\tvalid_0's binary_logloss: 1.02987\n",
      "[71]\tvalid_0's binary_logloss: 1.02989\n",
      "[72]\tvalid_0's binary_logloss: 1.02987\n",
      "[73]\tvalid_0's binary_logloss: 1.02975\n",
      "[74]\tvalid_0's binary_logloss: 1.03607\n",
      "[75]\tvalid_0's binary_logloss: 1.03594\n",
      "[76]\tvalid_0's binary_logloss: 1.03574\n",
      "[77]\tvalid_0's binary_logloss: 1.03612\n",
      "[78]\tvalid_0's binary_logloss: 1.03603\n",
      "[79]\tvalid_0's binary_logloss: 1.0361\n",
      "[80]\tvalid_0's binary_logloss: 1.0361\n",
      "[81]\tvalid_0's binary_logloss: 1.04067\n",
      "[82]\tvalid_0's binary_logloss: 1.04064\n",
      "[83]\tvalid_0's binary_logloss: 1.04063\n",
      "[84]\tvalid_0's binary_logloss: 1.04076\n",
      "[85]\tvalid_0's binary_logloss: 1.0407\n",
      "[86]\tvalid_0's binary_logloss: 1.04066\n",
      "[87]\tvalid_0's binary_logloss: 1.0405\n",
      "[88]\tvalid_0's binary_logloss: 1.04523\n",
      "[89]\tvalid_0's binary_logloss: 1.04686\n",
      "[90]\tvalid_0's binary_logloss: 1.05922\n",
      "[91]\tvalid_0's binary_logloss: 1.06881\n",
      "[92]\tvalid_0's binary_logloss: 1.08102\n",
      "[93]\tvalid_0's binary_logloss: 1.08246\n",
      "[94]\tvalid_0's binary_logloss: 1.08785\n",
      "[95]\tvalid_0's binary_logloss: 1.09412\n",
      "[96]\tvalid_0's binary_logloss: 1.09415\n",
      "[97]\tvalid_0's binary_logloss: 1.09393\n",
      "[98]\tvalid_0's binary_logloss: 1.09396\n",
      "[99]\tvalid_0's binary_logloss: 1.09398\n",
      "[100]\tvalid_0's binary_logloss: 1.09392\n",
      "[101]\tvalid_0's binary_logloss: 1.09404\n",
      "[102]\tvalid_0's binary_logloss: 1.09404\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.66671\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "oof = np.zeros(len(y))\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    print(type(train_index))\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "    # LightGBM のハイパーパラメータ\n",
    "    lgbm_params = {\n",
    "        # 多値分類問題\n",
    "        'objective': 'binary',\n",
    "\n",
    "    }\n",
    "\n",
    "    model = lgb.train(lgbm_params, lgb_train, \n",
    "                      valid_sets=lgb_eval,\n",
    "                     num_boost_round=10000,\n",
    "                     early_stopping_rounds=100)\n",
    "    \n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    oof[test_index] = y_pred\n",
    "\n",
    "oof_label = (oof > 0.5).astype(int)\n",
    "score = precision_score(y, oof_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642989173488249"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a moderate score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
